{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00566ce1",
   "metadata": {},
   "source": [
    "# BES Analysis in the Vertical Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad17dd",
   "metadata": {},
   "source": [
    "Import neccesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decb76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting_functions_BES import *\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a0c3c",
   "metadata": {},
   "source": [
    "Read BES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c02397de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BES data\n",
    "# (R, z) locations for the BES channels (view location)\n",
    "apdpos = np.asarray(xr.open_dataarray('Data\\\\shot29378_apdpos.nc'))\n",
    "\n",
    "fluct_data_from_file = xr.open_dataarray('Data\\\\shot29378_LH_fluct_data.nc')\n",
    "\n",
    "bes_time = np.asarray(fluct_data_from_file.coords['time']) # bes_time[0:992499]\n",
    "fluct_data = np.asarray(fluct_data_from_file) # fluct_data[0:31][0:992499]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb576f9",
   "metadata": {},
   "source": [
    "Load upper tangential $D_\\alpha$ data, used to identify crash times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e17a8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utda_from_file = xr.open_dataarray('Data/shot29378_upper_tan_dalpha.nc')\n",
    "\n",
    "utda_time = np.asarray(utda_from_file.coords['time'])\n",
    "utda_data = np.asarray(utda_from_file)\n",
    "\n",
    "# Trim to end of BES data\n",
    "end_idx = np.abs(utda_time-bes_time[-1]).argmin()-1 # -1 for safety\n",
    "utda_time = utda_time[:end_idx]\n",
    "utda_data = utda_data[:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d0454",
   "metadata": {},
   "source": [
    "Define interesting timeslices and thresholds for determining crash times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc5a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [[0.16,0.24], [0.36,0.54], [0.54,0.68]]\n",
    "thresholds = [0.04, 0.008, 0.02]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8b46c",
   "metadata": {},
   "source": [
    "Define function to find the k-f spectrum given a BES column and timeslice. Returns  the axes - frequencies in kHz, wavenumbers in m$^{-1}$ - and the spectrum itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93de05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kf_spec(col, timeslice): # Col is int from 0 to 7 . timeslice = [t1, t2], a 2x1 array\n",
    "    channels = []\n",
    "    for i in range(4): # For the given column, get each channel index\n",
    "        channels.append(i*8+col)\n",
    "    \n",
    "    space_array = [apdpos[i][1] for i in channels] # Get Z-coordinates of each channel\n",
    "    space_array = np.asarray(space_array)\n",
    "    spec = []\n",
    "    for ch in channels: # FFT each channel in time\n",
    "        fft = get_channel_fft(29378, bes_time, fluct_data, ch, timeslice, \"channel_fft\")\n",
    "        f_transform = fft[1]\n",
    "        spec.append(f_transform) # Each row of spec corresponds to a channel.\n",
    "    f_arr = fft[0] # Frequency array is the same for all of them so just save any one.\n",
    "    \n",
    "    spec = np.asarray(spec)\n",
    "    spec = np.transpose(spec) # Now each row is a time point as required by calc_kspecs\n",
    "    calc = calc_kspec(spec, space_array) # Get k-f spectrum\n",
    "    \n",
    "    kf_matrix = calc[0] # This contains the transform data\n",
    "    k_arr = calc[1] # This is the array of wavenumbers\n",
    "    \n",
    "    return f_arr, k_arr, kf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcb146",
   "metadata": {},
   "source": [
    "Function for plotting the k-f spectra as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fe61717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kf_spec_vertical(region, col, f_arr, k_arr, kf_matrix, fint=50.0, fmin=0.0, fmax=None, save=True):\n",
    "    if fmax == None:\n",
    "        fmax = np.max(f_arr)\n",
    "    # Only need to plot a section of the spectrum. At least half not needed.\n",
    "    kf_matrix = kf_matrix[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "    f_arr = f_arr[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "    \n",
    "    # Convert to array with rounded frequencies for easier of plotting.\n",
    "    kf_matrix_plot = pd.DataFrame(kf_matrix, index=np.around(f_arr,0), columns=np.around(k_arr,1))\n",
    "    \n",
    "    # For only plotting tick at every 50 kHz\n",
    "    interval = int(np.abs(f_arr - fint).argmin())\n",
    "\n",
    "    # Plot log of values so small enough range for features to be visible\n",
    "    sns.heatmap(np.log(np.abs(kf_matrix_plot)**2)[::-1], yticklabels=interval, cmap=\"plasma\", cbar_kws={\"label\": r\"$\\log\\vert S(f,k)\\vert^2$\"})\n",
    "    plt.title(\"Region \" + str(region) + \", t=\" + str(regions[region-1]) + \" s, Column \" + str(col) + \" (vertical)\")\n",
    "    plt.ylabel(\"Frequency [kHz]\")\n",
    "    plt.xlabel(r\"Wavenumber [m$^{-1}$]\")\n",
    "    if save == True:\n",
    "        plt.savefig(\"Plots/Good kf_specs/Vertical/\" + datestamp() + \"/kf_spec_reg_\" + str(region) + \"_col_\" + str(col) + \".png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60565b91",
   "metadata": {},
   "source": [
    "Calculate and plot k-f spectra for each region for each of the three left-most columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba67c019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(3):\\n    for col in range(3):\\n        tmp = get_kf_spec(col,regions[region])\\n        plot_kf_spec_vertical(region+1, col, tmp[0], tmp[1], tmp[2], fmax=250.0, save=False)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(3):\n",
    "    for col in range(3):\n",
    "        tmp = get_kf_spec(col,regions[region])\n",
    "        plot_kf_spec_vertical(region+1, col, tmp[0], tmp[1], tmp[2], fmax=250.0, save=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136df13",
   "metadata": {},
   "source": [
    "Function for summing contributions for each wavenumber OR frequency to produce a spectrum of FFT against frequency OR wavenumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274a0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_sum(kf_matrix, keep_var): # keep_var is the variable not summed over. E.g. if f it sums ks for each f.\n",
    "    if keep_var == \"k\":\n",
    "        spec = np.sum(kf_matrix, axis=0)\n",
    "    elif keep_var == \"f\":\n",
    "        spec = np.sum(kf_matrix, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Bad argument keep_var = \" + keep_var)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b1a64",
   "metadata": {},
   "source": [
    "Function for plotting the spectrum of FFT against $f$ or $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac53c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kf_sum(region, col, keep_var, kf_axis, spec, save=True):  \n",
    "    \n",
    "    # If spec is S(f) limit axes to show points above 1% of max value, so shape clearer.\n",
    "    if keep_var == \"f\":\n",
    "        plt.plot(kf_axis, np.log(np.abs(spec)**2), color=\"k\", linewidth=0.05)\n",
    "        spec_max = np.max(spec)\n",
    "        idx = 0\n",
    "        for i in spec:\n",
    "            if i > 0.01*spec_max:\n",
    "                xlim = kf_axis[idx]\n",
    "                break\n",
    "            idx += 1\n",
    "        plt.xlim([-xlim,xlim])\n",
    "        plt.xlabel(\"Frequency [kHz]\")\n",
    "        plt.ylabel(r\"$\\log\\vert\\sum_kS(k,f)\\vert^2=\\log\\vert S(f)\\vert^2$\")\n",
    "    else:\n",
    "        plt.plot(kf_axis, np.abs(spec), color=\"k\", linewidth=0.5)\n",
    "        plt.xlabel(r\"Wavenumber [m$^{-1}$]\")\n",
    "        plt.ylabel(r\"$\\log\\vert\\sum_fS(k,f)\\vert^2=\\log\\vert S(k)\\vert^2$\")\n",
    "    plt.xlim([-200,200])\n",
    "    plt.title(\"Region \" + str(region) + \", t=\" + str(regions[region-1]) + \" s, Column \" + str(col) + \" (vertical)\")\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(\"Plots/kf-summed/Vertical/\" + datestamp() + \"/\" + keep_var + \"-sum_reg_\" + str(region) + \"_col_\" + str(col) + \".pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44187c2",
   "metadata": {},
   "source": [
    "Function to sum points over a 1D array in a given distinct window. new_freqs is 1/window_size of freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f7d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_box_sum(spec, freqs, window_length):\n",
    "    spec_smooth = []\n",
    "    new_freqs = []\n",
    "    window_hw = int(np.floor(window_length/2))\n",
    "\n",
    "    for i in range(int(np.ceil(window_length/2)),len(spec)-window_hw,window_length): # From first to last midpoint\n",
    "        window_sum = 0\n",
    "        for j in range(i-window_hw, i+window_hw+1): # +1 to include the end point\n",
    "            window_sum += spec[j]\n",
    "        spec_smooth.append(window_sum)\n",
    "        new_freqs.append(freqs[i])\n",
    "    return new_freqs, spec_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10389f",
   "metadata": {},
   "source": [
    "Plot $S(f)$ using above feature-enhancing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b19b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(3):\\n    for col in range(3):\\n        tmp = get_kf_spec(col,regions[region])\\n        spec = kf_sum(tmp[2], \"f\")\\n        plot_kf_sum(region+1, col+1, \"f\", spec_box_sum(spec, tmp[0], 10)[0], spec_box_sum(spec, tmp[0], 10)[1], save=True)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(3):\n",
    "    for col in range(3):\n",
    "        tmp = get_kf_spec(col,regions[region])\n",
    "        spec = kf_sum(tmp[2], \"f\")\n",
    "        plot_kf_sum(region+1, col+1, \"f\", spec_box_sum(spec, tmp[0], 10)[0], spec_box_sum(spec, tmp[0], 10)[1], save=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25213b03",
   "metadata": {},
   "source": [
    "Function to do same as spec_box_sum but for 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b0d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_spec_box_sum(f_arr, k_arr, kf_matrix, window_length):\n",
    "    kf_matrix = np.transpose(kf_matrix)\n",
    "    new_matrix = []\n",
    "    \n",
    "    for i in kf_matrix:\n",
    "        summed = spec_box_sum(i, f_arr, window_length)\n",
    "        new_matrix.append(summed[1])\n",
    "    return np.asarray(summed[0]), k_arr, np.transpose(np.asarray(new_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196f160",
   "metadata": {},
   "source": [
    "Make kf spectra plots where frequencies summed over a number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66cf7438",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(3):\\n    for col in range(3):\\n        tmp = get_kf_spec(col,regions[region])\\n        blocked = kf_spec_box_sum(tmp[0], tmp[1], tmp[2], 10)\\n        plot_kf_spec_vertical(region+1, col+1, blocked[0], blocked[1], blocked[2], fmax=250, save=False)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(3):\n",
    "    for col in range(3):\n",
    "        tmp = get_kf_spec(col,regions[region])\n",
    "        blocked = kf_spec_box_sum(tmp[0], tmp[1], tmp[2], 10)\n",
    "        plot_kf_spec_vertical(region+1, col+1, blocked[0], blocked[1], blocked[2], fmax=250, save=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a84c4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kf_spec_vert_cond(region, col, f_arr, k_arr, kf_matrix, fint=50.0, fmin=0.0, fmax=None, save=True, fn=\"\"):\n",
    "    if fmax == None:\n",
    "        fmax = np.max(f_arr)\n",
    "\n",
    "    # Only need to plot a section of the spectrum. At least half not needed.\n",
    "    kf_matrix = kf_matrix[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "    f_arr = f_arr[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "\n",
    "    # Convert to array with rounded frequencies for easier of plotting.\n",
    "    kf_matrix_plot = pd.DataFrame(kf_matrix, index=np.around(f_arr,0), columns=np.around(k_arr,1))\n",
    "    \n",
    "    # For only plotting tick at every 50 kHz\n",
    "    interval = int(np.abs(f_arr - fint).argmin())\n",
    "\n",
    "    # Plot log of values so small enough range for features to be visible\n",
    "    sns.heatmap(np.log(np.abs(kf_matrix_plot)**2)[::-1], yticklabels=interval, cmap=\"plasma\", cbar_kws={\"label\": r\"$\\log\\vert S(k|f)\\vert^2$\"})\n",
    "    plt.title(\"Region \" + str(region) + \", t=\" + str(regions[region-1]) + \" s, Column \" + str(col) + \" (vertical)\")\n",
    "    plt.ylabel(\"Frequency [kHz]\")\n",
    "    plt.xlabel(r\"Wavenumber [m$^{-1}$]\")\n",
    "    if save == True:\n",
    "        plt.savefig(\"Plots/kf-conditional/Vertical/\" +  datestamp() + \"/kf_cond_vert_spec_reg_\" + str(region) + \"_col_\" + str(col) + \"_\" + fn + \".png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313845c",
   "metadata": {},
   "source": [
    "Function to convert $S(f,k) \\to S(k|f)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb31c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_kf(f_arr, kf_matrix, fmin=0.0, fmax=None):\n",
    "    if fmax == None:\n",
    "        fmax = np.max(f_arr)\n",
    "\n",
    "    kf_matrix = kf_matrix[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "    f_arr = f_arr[(np.abs(f_arr - fmin)).argmin():(np.abs(f_arr - fmax)).argmin()]\n",
    "    spec = np.transpose(kf_matrix)/np.sum(kf_matrix,axis=1)\n",
    "\n",
    "    return f_arr, np.transpose(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81da65",
   "metadata": {},
   "source": [
    "Produce plots of $S(k|f)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8d6ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(3):\\n    for col in range(3):\\n        tmp = get_kf_spec(col,regions[region])\\n        spec = normalise_kf(tmp[0], tmp[2], fmax=250.0)\\n        blocked = kf_spec_box_sum(spec[0], tmp[1], spec[1], 10)\\n        plot_kf_spec_vert_cond(region+1, col+1, blocked[0], blocked[1], blocked[2], fmax=250, save=True)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(3):\n",
    "    for col in range(3):\n",
    "        tmp = get_kf_spec(col,regions[region])\n",
    "        spec = normalise_kf(tmp[0], tmp[2], fmax=250.0)\n",
    "        blocked = kf_spec_box_sum(spec[0], tmp[1], spec[1], 10)\n",
    "        plot_kf_spec_vert_cond(region+1, col+1, blocked[0], blocked[1], blocked[2], fmax=250, save=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e34a3",
   "metadata": {},
   "source": [
    "Function to get moving average of 1D array - not currently in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70bfaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_rolling_avg(spec, window_length):\n",
    "    spec_smooth = []\n",
    "    window_mid = int(np.floor(window_length/2))\n",
    "    window_left = int(np.floor(window_length/2))\n",
    "    window_right = int(np.ceil(window_length/2))\n",
    "    \n",
    "    for i in range(window_left,len(spec)-window_right):\n",
    "        window_sum = 0\n",
    "        for j in range(window_mid-window_left, window_mid+window_right):\n",
    "            window_sum += spec[j]\n",
    "        spec_smooth.append(window_sum/window_length)\n",
    "        window_mid += 1\n",
    "    return spec_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee7895",
   "metadata": {},
   "source": [
    "Making $k$-$f$ spectra for focussing on crashes only.\n",
    "\n",
    "Function to short-time FFT data, sum up each column and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9abfaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_bes_fluct_spectrogram(bes_time, fluct_data, region, col, timeslice, n, freq_lims=[0.0, 200.0], vlines=None, plot=False, save=True):\n",
    "    # plot the BES fluctuation data spectrogram for one or more channels, L. Howlett adapted by A. Caplan\n",
    "    idx1 = (np.abs(bes_time - timeslice[0])).argmin()\n",
    "    idx2 = (np.abs(bes_time - timeslice[1])).argmin()\n",
    "    channels = []\n",
    "    for i in range(4): # For the given column, get each channel index\n",
    "        channels.append(i*8+col)\n",
    "    \n",
    "    freq, times, Sxx = sig.spectrogram(fluct_data[:,idx1:idx2], fs=f_samp, \n",
    "                                       nperseg=(2 ** n), scaling='spectrum')\n",
    "    \n",
    "    num_channels = len(channels)\n",
    "    new_lim = int(14 * (2 ** (n - 7)))\n",
    "    new_lim = len(freq)-1\n",
    "    \n",
    "    summed_Sxx = np.asarray(Sxx[channels[0]][:new_lim,:])\n",
    "    for ch in channels[1:]:\n",
    "        summed_Sxx += Sxx[ch][:new_lim,:]\n",
    "    \n",
    "    if plot == True:\n",
    "        figure, axes = plt.subplots(1, 1, sharex=True, \n",
    "                                    figsize=(15, 7))\n",
    "        axes.set_title('Region ' + str(region+1) + ', Sum of col ' + str(col+1) + ', n=' + \n",
    "            str(int(2 ** n)), fontsize=32)    \n",
    "\n",
    "        ct = axes.contourf(times + bes_time[idx1], 0.001 * freq[:new_lim], \n",
    "               summed_Sxx, 16, cmap=plt.get_cmap('plasma'), levels=[10**(i/10) for i in range(-80,10,5)],\n",
    "                norm=(colors.LogNorm()))\n",
    "\n",
    "        if vlines != None:\n",
    "            for line in vlines:\n",
    "                axes.vlines(line[0], 0, 200, \"green\", linestyle=\"dashed\", linewidth=0.5)\n",
    "                axes.vlines(line[1], 0, 200, \"red\", linestyle=\"dashed\", linewidth=0.5)\n",
    "        axes.set_ylim(freq_lims)\n",
    "        axes.tick_params(axis='y', labelsize=22)\n",
    "        axes.set_ylabel(r'$f$ [kHz]', fontsize=24)\n",
    "        cbar = figure.colorbar(ct, shrink=0.9, label=\"Strength [a.u.]\")\n",
    "        axes.tick_params(axis='x', labelsize=24)\n",
    "        axes.set_xlabel('time [s]', fontsize=26)\n",
    "        axes.set_xlim(timeslice)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save==True:\n",
    "            plt.savefig(\"Plots/Spectrograms/Vertical/\" +  datestamp() + \"/stftt_colsum_reg_\" + str(region+1) + \"_col_\" + str(col+1) + \".png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    return freq, times + bes_time[idx1], summed_Sxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803896fb",
   "metadata": {},
   "source": [
    "Function to determine timeslices in-between crashed based on input on timeslices centred on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96ec81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_slices(slices):\n",
    "    inactives = []\n",
    "    width = slices[0][1]-slices[0][0]\n",
    "    for idx in range(len(slices)-1):\n",
    "        if abs(slices[idx][1] - slices[idx+1][0]) > width:\n",
    "            inactives.append([slices[idx][1], slices[idx+1][0]])\n",
    "            \n",
    "    inactives = np.asarray(inactives)\n",
    "    min_width = np.min(inactives[:,1] - np.min(inactives[:,0]))\n",
    "    equal_widths = []\n",
    "    for i in inactives:\n",
    "        midpoint = np.mean(i)\n",
    "        equal_widths.append([midpoint-0.5*min_width, midpoint+0.5*min_width])\n",
    "    \n",
    "    print(min_width)\n",
    "    \n",
    "    return equal_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3567f9",
   "metadata": {},
   "source": [
    "Get strength along line of all time at a given frequency. Use this to work out times of crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a27b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_line(freq, times, Sxx, f, plot=False, invert=False):\n",
    "    fidx = np.abs(freq-f).argmin() # index of line at f\n",
    "    line = smooth(Sxx[fidx,:],10)\n",
    "    \n",
    "    significant = [] # indices of peaks\n",
    "    # Based on max of middle section to handle some errors \n",
    "    for i in range(len(line)):\n",
    "        if line[i] > 0.4*np.max(line[len(line)*20//100:len(line)*80//100]):\n",
    "            significant.append(i)\n",
    "\n",
    "    width = np.max(np.diff(significant))//10\n",
    "    slices = [] # Pairs of values, with each significant in the middle\n",
    "    \n",
    "    # If peak detected too close to end of region, remove last peak from consideration\n",
    "    windows_inside = False\n",
    "    while windows_inside == False:\n",
    "        if significant[-1] + width >= len(line):\n",
    "            significant = significant[:-1]\n",
    "        else:\n",
    "            windows_inside = True\n",
    "    \n",
    "    for i in significant:\n",
    "        slices.append([times[i-width], times[i+width]])\n",
    "    \n",
    "    if invert == True:\n",
    "        slices = invert_slices(slices)\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.plot(times,line, linewidth=0.75)\n",
    "        plt.plot([times[i] for i in significant], [line[i] for i in significant], \"x\")\n",
    "        plt.vlines([i[0] for i in slices], 0, np.max(line), \"k\", \"dashed\", linewidth=0.5)\n",
    "        plt.vlines([i[1] for i in slices], 0, np.max(line), \"b\", \"dashed\",linewidth=0.5)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa298222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_box_sum(bes_time, fluct_data, region, col, timeslice, n=8, plot=True, save=False):\n",
    "    stftt = sum_bes_fluct_spectrogram(bes_time, fluct_data, region, col, timeslice, n, freq_lims=[0.0, 300.0], plot=False, save=False)\n",
    "    summed = kf_spec_box_sum(stftt[0], stftt[1], stftt[2], 4)\n",
    "    freq = summed[0]\n",
    "    times = summed[1]\n",
    "    summed_Sxx = summed[2]\n",
    "    \n",
    "    if plot == True:\n",
    "        figure, axes = plt.subplots(1, 1, sharex=True, \n",
    "                                    figsize=(15, 7))\n",
    "        axes.set_title('Region ' + str(region+1) + ', Sum of col ' + str(col+1) + ', n=' + \n",
    "            str(int(2 ** n)), fontsize=32)    \n",
    "\n",
    "        ct = axes.contourf(times, 0.001 * freq, \n",
    "               summed_Sxx, 16, cmap=plt.get_cmap('plasma'), levels=[10**(i/10) for i in range(-60,10,5)],\n",
    "                norm=(colors.LogNorm()))\n",
    "\n",
    "        axes.set_ylim([0.0,250.0])\n",
    "        axes.tick_params(axis='y', labelsize=22)\n",
    "        axes.set_ylabel(r'$f$ [kHz]', fontsize=24)\n",
    "        cbar = figure.colorbar(ct, shrink=0.9, label=\"Strength [a.u.]\")\n",
    "        axes.tick_params(axis='x', labelsize=24)\n",
    "        axes.set_xlabel('time [s]', fontsize=26)\n",
    "        axes.set_xlim(timeslice)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save==True:\n",
    "            plt.savefig(\"Plots/Spectrograms/Vertical/\" +  datestamp() + \"/stftt_colsum_reg_\" + str(region+1) + \"_col_\" + str(col+1) + \".png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    return freq, times, summed_Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4ecbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_peak_only(region, col, timeslice, line, conditional=True, box_sum=None, plot=True, save=False):\n",
    "    # Find times where lots of frequencies appear\n",
    "    stftt = spectrogram_box_sum(bes_time, fluct_data, region, col, timeslice, n=8, plot=True, save=False)\n",
    "    small_slices = get_spectrogram_line(stftt[0], stftt[1], stftt[2], line*1000, plot=True)\n",
    "    \n",
    "    # FFT each spike and combine into one\n",
    "    first_spike = get_kf_spec(col,small_slices[0])\n",
    "    peak_sum_kf_matrix = np.asarray(first_spike[2])\n",
    "    f_arr = np.asarray(first_spike[0])\n",
    "    k_arr = np.asarray(first_spike[1])\n",
    "\n",
    "    for peak in range(1,len(small_slices)):\n",
    "        peak_sum_kf_matrix += np.abs(get_kf_spec(col,small_slices[peak])[2])\n",
    "        #plot_kf_spec_vertical(region, col, f_arr, k_arr, peak_sum_kf_matrix,fmax=250.0,save=False)\n",
    "\n",
    "    if conditional:\n",
    "        normed_spec = normalise_kf(f_arr, peak_sum_kf_matrix)\n",
    "        peak_sum_kf_matrix = normed_spec[1]\n",
    "        f_arr = normed_spec[0]\n",
    "    \n",
    "    if box_sum != None:\n",
    "        blocked_spec = kf_spec_box_sum(f_arr, k_arr, peak_sum_kf_matrix, box_sum)\n",
    "        f_arr = blocked_spec[0]\n",
    "        k_arr = blocked_spec[1]\n",
    "        peak_sum_kf_matrix = blocked_spec[2]\n",
    "\n",
    "    if plot:\n",
    "        if conditional:\n",
    "            plot_kf_spec_vert_cond(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save, fn=\"pm\")\n",
    "        else:\n",
    "            plot_kf_spec_vertical(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c51fb1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for region in range(1,2):\n",
    "#    for col in range(2,3):\n",
    "#        fft_peak_only(region, col, regions[region], 150.0, conditional=True, box_sum=5, plot=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92f7c693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for col in range(8):\\n    sum_bes_fluct_spectrogram(bes_time, fluct_data, 2, col, [0.56,0.58], 8, plot=True, save=False)\\nprint(\"\")'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for col in range(8):\n",
    "    sum_bes_fluct_spectrogram(bes_time, fluct_data, 2, col, [0.56,0.58], 8, plot=True, save=False)\n",
    "print(\"\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eaf539",
   "metadata": {},
   "source": [
    "Function to get the cross-correlation function for two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68b55c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_corr(refch, ch, bes_time, fluct_data, timeslice):\n",
    "    idx1 = np.abs(bes_time - timeslice[0]).argmin()\n",
    "    idx2 = np.abs(bes_time - timeslice[1]).argmin()\n",
    "    ch_data = fluct_data[ch, idx1:idx2]\n",
    "    ref_data = fluct_data[refch, idx1:idx2]\n",
    "    dt = np.mean(np.diff(bes_time[idx1:idx2]))\n",
    "    return dt*sig.correlation_lags(len(ch_data), len(ref_data)), sig.correlate(ref_data, ch_data, method=\"fft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13df6161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ref_ch = 0\\nlabels = []\\npeaks = []\\nfor row in range(4):\\n    cctd = get_cross_corr(ref_ch, ref_ch+8*row, bes_time, fluct_data, regions[0])\\n    peaks.append(cctd[0][cctd[1].argmax()]) # Peaks of cross-correlation function\\n    print((apdpos[ref_ch][1] - apdpos[ref_ch+8*row][1])/peaks[-1])\\n    plt.plot(1000*cctd[0], cctd[1], linewidth=0.5)\\n    labels.append(\"Ch \" + str(ref_ch) + \"-\" + str(ref_ch+8*row))\\nplt.xlim(left=-0.025,right=0.025)\\nplt.ylabel(\"Cross Correlation [a.u.]\")\\nplt.xlabel(\"Lag [ms]\")\\nplt.legend(labels)\\n#plt.savefig(\"small_cc.png\", dpi=300)\\nplt.show()'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ref_ch = 0\n",
    "labels = []\n",
    "peaks = []\n",
    "for row in range(4):\n",
    "    cctd = get_cross_corr(ref_ch, ref_ch+8*row, bes_time, fluct_data, regions[0])\n",
    "    peaks.append(cctd[0][cctd[1].argmax()]) # Peaks of cross-correlation function\n",
    "    print((apdpos[ref_ch][1] - apdpos[ref_ch+8*row][1])/peaks[-1])\n",
    "    plt.plot(1000*cctd[0], cctd[1], linewidth=0.5)\n",
    "    labels.append(\"Ch \" + str(ref_ch) + \"-\" + str(ref_ch+8*row))\n",
    "plt.xlim(left=-0.025,right=0.025)\n",
    "plt.ylabel(\"Cross Correlation [a.u.]\")\n",
    "plt.xlabel(\"Lag [ms]\")\n",
    "plt.legend(labels)\n",
    "#plt.savefig(\"small_cc.png\", dpi=300)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b1c51",
   "metadata": {},
   "source": [
    "Function to FFT and plot timeslices not containing crashes.\n",
    "\n",
    "In a later version of the code, this function and fft_peak_only can probably be combined since they only differ by one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adbb9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_exclude_peaks(region, col, timeslice, line, conditional=True, box_sum=None, plot=True, save=False):\n",
    "    # Find times where lots of frequencies appear\n",
    "    stftt = spectrogram_box_sum(bes_time, fluct_data, region, col, timeslice, n=8, plot=True, save=False)\n",
    "    small_slices = get_spectrogram_line(stftt[0], stftt[1], stftt[2], line*1000, plot=True, invert=True)\n",
    "    #small_slices = invert_slices(small_slices) # This line is the only important difference\n",
    "    \n",
    "    # FFT each spike and combine into one\n",
    "    first_spike = get_kf_spec(col,small_slices[0])\n",
    "    peak_sum_kf_matrix = np.asarray(first_spike[2])\n",
    "    f_arr = np.asarray(first_spike[0])\n",
    "    k_arr = np.asarray(first_spike[1])\n",
    "\n",
    "    for peak in range(1,len(small_slices)):\n",
    "        peak_sum_kf_matrix += np.abs(get_kf_spec(col,small_slices[peak])[2])\n",
    "        #plot_kf_spec_vertical(region, col, f_arr, k_arr, peak_sum_kf_matrix,fmax=250.0,save=False)\n",
    "\n",
    "    if conditional:\n",
    "        normed_spec = normalise_kf(f_arr, peak_sum_kf_matrix)\n",
    "        peak_sum_kf_matrix = normed_spec[1]\n",
    "        f_arr = normed_spec[0]\n",
    "    \n",
    "    if box_sum != None:\n",
    "        blocked_spec = kf_spec_box_sum(f_arr, k_arr, peak_sum_kf_matrix, box_sum)\n",
    "        f_arr = blocked_spec[0]\n",
    "        k_arr = blocked_spec[1]\n",
    "        peak_sum_kf_matrix = blocked_spec[2]\n",
    "\n",
    "    if plot:\n",
    "        if conditional:\n",
    "            plot_kf_spec_vert_cond(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save, fn=\"inactive\")\n",
    "        else:\n",
    "            plot_kf_spec_vertical(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7314ecfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(3):\\n    for col in range(8):\\n        fft_exclude_peaks(region, col, regions[region], 150.0, conditional=True, box_sum=5, plot=True, save=False)'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(3):\n",
    "    for col in range(8):\n",
    "        fft_exclude_peaks(region, col, regions[region], 150.0, conditional=True, box_sum=5, plot=True, save=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14c996aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stftt = spectrogram_box_sum(bes_time, fluct_data, 1, 2, regions[1], n=8, plot=True, save=False)\n",
    "#small_slices = get_spectrogram_line(stftt[0], stftt[1], stftt[2], 150.0*1000, plot=True, invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b144444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_slices = get_spectrogram_line(stftt[0], stftt[1], stftt[2], 150.0*1000, plot=True, invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57955e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_finder(freq, times, Sxx, f, plot=False, invert=False):\n",
    "    fidx = np.abs(freq-f).argmin() # index of line at f\n",
    "    line = smooth(Sxx[fidx,:],5)\n",
    "    \n",
    "    significant = [] # indices of peaks\n",
    "    # Based on max of middle section to handle some errors \n",
    "    for i in range(len(line)):\n",
    "        if line[i] > 0.3*np.max(line[len(line)*20//100:len(line)*80//100]):\n",
    "            significant.append(i)\n",
    "\n",
    "    width = np.max(np.diff(significant))//10\n",
    "    slices = [] # Pairs of values, with each significant in the middle\n",
    "    \n",
    "    # If peak detected too close to end of region, remove last peak from consideration\n",
    "    windows_inside = False\n",
    "    while windows_inside == False:\n",
    "        if significant[-1] + width >= len(line):\n",
    "            significant = significant[:-1]\n",
    "        else:\n",
    "            windows_inside = True\n",
    "            \n",
    "    for i in significant:\n",
    "        slices.append([times[i-width], times[i+width]])\n",
    "    \n",
    "    plt.plot(times, line)\n",
    "    plt.plot([times[i] for i in significant], [line[i] for i in significant], \"x\")\n",
    "    plt.vlines([i[0] for i in slices], 0, np.max(line), \"k\", \"dashed\", linewidth=0.5)\n",
    "    plt.vlines([i[1] for i in slices], 0, np.max(line), \"b\", \"dashed\",linewidth=0.5)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4b2fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_finder(stftt[0], stftt[1], stftt[2], 150.0*1000, plot=True, invert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dfb6e4",
   "metadata": {},
   "source": [
    "Function to determine, based on upper tangential $D_\\alpha$ data, times of the crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "166a5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crash_times(utda_time, utda_data, threshold, timeslice):\n",
    "    timestep = np.mean(np.diff(utda_time))\n",
    "    idx_jump = int(0.0015//timestep)\n",
    "    idx1 = (np.abs(utda_time - timeslice[0])).argmin()\n",
    "    idx2 = (np.abs(utda_time - timeslice[1])).argmin()\n",
    "    ddata = np.gradient(utda_data)\n",
    "    \n",
    "    check_idx = idx1\n",
    "    windows = []\n",
    "    while check_idx <= idx2:\n",
    "        if ddata[check_idx] > threshold:\n",
    "            windows.append([check_idx-idx_jump, check_idx+idx_jump])\n",
    "            check_idx += idx_jump\n",
    "        else:\n",
    "            check_idx += 1\n",
    "    \n",
    "    crash_times = []\n",
    "    for crash in windows:\n",
    "        max_idx = crash[0] + np.where(ddata[crash[0]:crash[1]] == np.max(ddata[crash[0]:crash[1]]))[0][0]\n",
    "        crash_times.append(utda_time[max_idx])\n",
    "    return crash_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c18c9",
   "metadata": {},
   "source": [
    "Function to work out window just before/after crash. Default is to return pre-crash but negative shifts give window just after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "18bdbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crash_adjacent_window(utda_time, utda_data, threshold, timeslice, start_shift=5e-3, end_shift = 1e-3):\n",
    "    crash_times = get_crash_times(utda_time, utda_data, threshold, timeslice)\n",
    "    windows = []\n",
    "    \n",
    "    for i in crash_times:\n",
    "        windows.append([i-start_shift, i-end_shift])\n",
    "        \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58a96345",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_crash_windows = {}\n",
    "for region in range(len(regions)):\n",
    "    pre_crash_windows[region] = get_crash_adjacent_window(utda_time, utda_data, thresholds[region], regions[region])\n",
    "    sum_bes_fluct_spectrogram(bes_time, fluct_data, region, 0, regions[region], 8, vlines=pre_crash_windows[region], plot=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2be023a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_pre_peak(region, col, conditional=True, box_sum=None, plot=True, save=False):\n",
    "    # Find times where lots of frequencies appear\n",
    "    small_slices = pre_crash_windows[region]\n",
    "    \n",
    "    # FFT each spike and combine into one\n",
    "    first_spike = get_kf_spec(col,small_slices[0])\n",
    "    peak_sum_kf_matrix = np.asarray(first_spike[2])\n",
    "    f_arr = np.asarray(first_spike[0])\n",
    "    k_arr = np.asarray(first_spike[1])\n",
    "\n",
    "    for peak in range(1,len(small_slices)):\n",
    "        peak_sum_kf_matrix += np.abs(get_kf_spec(col,small_slices[peak])[2])\n",
    "        #plot_kf_spec_vertical(region, col, f_arr, k_arr, peak_sum_kf_matrix,fmax=250.0,save=False)\n",
    "\n",
    "    if conditional:\n",
    "        normed_spec = normalise_kf(f_arr, peak_sum_kf_matrix)\n",
    "        peak_sum_kf_matrix = normed_spec[1]\n",
    "        f_arr = normed_spec[0]\n",
    "    \n",
    "    if box_sum != None:\n",
    "        blocked_spec = kf_spec_box_sum(f_arr, k_arr, peak_sum_kf_matrix, box_sum)\n",
    "        f_arr = blocked_spec[0]\n",
    "        k_arr = blocked_spec[1]\n",
    "        peak_sum_kf_matrix = blocked_spec[2]\n",
    "\n",
    "    if plot:\n",
    "        if conditional:\n",
    "            plot_kf_spec_vert_cond(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save, fn=\"\")\n",
    "        else:\n",
    "            plot_kf_spec_vertical(region+1, col+1, f_arr, k_arr, peak_sum_kf_matrix, fmax=250.0, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e7065e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in range(len(regions)):\n",
    "    for col in range(8):\n",
    "        fft_pre_peak(region, col, conditional=False, box_sum=8, plot=True, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
