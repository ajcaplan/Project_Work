{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd046c4",
   "metadata": {},
   "source": [
    "# Learning to work with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e885d",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0d2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting_functions_BES import *\n",
    "import matplotlib.path as mplPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398139f7",
   "metadata": {},
   "source": [
    "Read $D_\\alpha$ and density data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfb0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for density, Dalpha and upper tangential Dalpha\n",
    "dalpha_from_file = xr.open_dataarray('Data/shot29378_dalpha.nc')\n",
    "\n",
    "dalpha_time = np.asarray(dalpha_from_file.coords['time'])\n",
    "dalpha_data = np.asarray(dalpha_from_file)\n",
    "\n",
    "density_from_file = xr.open_dataarray('Data/shot29378_density.nc')\n",
    "\n",
    "density_time = np.asarray(density_from_file.coords['time'])\n",
    "density_data = np.asarray(density_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c2cae",
   "metadata": {},
   "source": [
    "Read equilibria data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beeb279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for equilibria\n",
    "equilib_from_file = xr.open_dataarray('Data/shot29378_equilibria.nc')\n",
    "\n",
    "equilib_time = np.asarray(equilib_from_file.coords['time'])\n",
    "equilib_R = np.asarray(equilib_from_file.coords['R'])\n",
    "equilib_Z = np.asarray(equilib_from_file.coords['Z'])\n",
    "equilib_psi = np.asarray(equilib_from_file) # Contains 135 length-65 arrays [0:134][0:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7eb76",
   "metadata": {},
   "source": [
    "Read BES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621d87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BES data\n",
    "# (R, z) locations for the BES channels (view location)\n",
    "apdpos = np.asarray(xr.open_dataarray('Data/shot29378_apdpos.nc'))\n",
    "\n",
    "fluct_data_from_file = xr.open_dataarray('Data/shot29378_LH_fluct_data.nc')\n",
    "\n",
    "bes_time = np.asarray(fluct_data_from_file.coords['time'])\n",
    "fluct_data = np.asarray(fluct_data_from_file)\n",
    "# fluct_data has 4 rows, 8 channels (mapped to apdpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1079fea",
   "metadata": {},
   "source": [
    "Contour plot of flux surfaces from equilibrium data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de362d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.contour(equilib_R, equilib_Z, equilib_psi[time_idx], np.linspace(0, 1, 21))\\nplt.title(\"Time = \" + str(equilib_time[time_idx]))\\nplt.xlabel(\"$R$ / m\")\\nplt.ylabel(\"$Z$ / m\")\\nplt.colorbar()\\nplt.show()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_idx = 50 # 0 to 132\n",
    "\"\"\"plt.contour(equilib_R, equilib_Z, equilib_psi[time_idx], np.linspace(0, 1, 21))\n",
    "plt.title(\"Time = \" + str(equilib_time[time_idx]))\n",
    "plt.xlabel(\"$R$ / m\")\n",
    "plt.ylabel(\"$Z$ / m\")\n",
    "plt.colorbar()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe58f05",
   "metadata": {},
   "source": [
    "Generate plot of fluctation against time for a given BES channel from fluctuation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f5cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = 5 # 0 to 31\n",
    "channel_coords = apdpos[channel_id] # Get corresponding (R,Z) coordinates\n",
    "\n",
    "#plot_bes_fluctuations(29378, bes_time, fluct_data, [0.36,0.54], [0,1], \"fluct_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9f218",
   "metadata": {},
   "source": [
    "Generate grid of channels and fluctuation value at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f2656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.matshow(channels)\\nplt.title(\"Time =\" + str(bes_time[time_idx]))\\nplt.xlabel(\"Channel\")\\nplt.ylabel(\"Channel\")\\nplt.colorbar()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_idx=992499 # 0 to 992499\n",
    "channels = [] # 32x1 array of the 32 channels\n",
    "for channel in fluct_data:\n",
    "    channels.append(channel[time_idx])\n",
    "channels = np.reshape(channels, (4,8)) # Convert 32x1 array to 8x4, presumed to be correct\n",
    "\"\"\"plt.matshow(channels)\n",
    "plt.title(\"Time =\" + str(bes_time[time_idx]))\n",
    "plt.xlabel(\"Channel\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b128faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_bes_locs(29378, apdpos, equilib_time[50], equilib_R, equilib_Z, equilib_psi[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead18528",
   "metadata": {},
   "source": [
    "Plotting $D_\\alpha$ data (density) to identify timeslices of interest where there appears to be repetitive behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd60cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"figure, axes = plt.subplots(2, 1, sharex=True, \\n                                figsize=(15, 6))\\naxes[0].plot(dalpha_time, dalpha_data, 'k', linewidth=0.8)\\naxes[1].plot(density_time, density_data, 'k', linewidth=0.8)\\naxes[1].tick_params(axis='x', labelsize=24)\\naxes[1].set_xlabel('time [s]', fontsize=26)\\naxes[1].set_xlim([dalpha_time[0], dalpha_time[-1]])\\nplt.subplots_adjust(wspace=0, hspace=0)\\nplt.show()\\nplt.close()\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"figure, axes = plt.subplots(2, 1, sharex=True, \n",
    "                                figsize=(15, 6))\n",
    "axes[0].plot(dalpha_time, dalpha_data, 'k', linewidth=0.8)\n",
    "axes[1].plot(density_time, density_data, 'k', linewidth=0.8)\n",
    "axes[1].tick_params(axis='x', labelsize=24)\n",
    "axes[1].set_xlabel('time [s]', fontsize=26)\n",
    "axes[1].set_xlim([dalpha_time[0], dalpha_time[-1]])\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n",
    "plt.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9098ee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot_dalpha(29378, dalpha_time, dalpha_data, [0.16,0.24], \"region_1\")\\nplot_density(29378, density_time, density_data, [0.16,0.24], \"region_1\")\\n\\nplot_dalpha(29378, dalpha_time, dalpha_data, [0.36,0.54], \"region_2\")\\nplot_density(29378, density_time, density_data, [0.36,0.54], \"region_2\")\\n\\nplot_dalpha(29378, dalpha_time, dalpha_data, [0.54,0.68], \"region_3\")\\nplot_density(29378, density_time, density_data, [0.54,0.68], \"region_3\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plot_dalpha(29378, dalpha_time, dalpha_data, [0.16,0.24], \"region_1\")\n",
    "plot_density(29378, density_time, density_data, [0.16,0.24], \"region_1\")\n",
    "\n",
    "plot_dalpha(29378, dalpha_time, dalpha_data, [0.36,0.54], \"region_2\")\n",
    "plot_density(29378, density_time, density_data, [0.36,0.54], \"region_2\")\n",
    "\n",
    "plot_dalpha(29378, dalpha_time, dalpha_data, [0.54,0.68], \"region_3\")\n",
    "plot_density(29378, density_time, density_data, [0.54,0.68], \"region_3\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000fe73",
   "metadata": {},
   "source": [
    "How uniformly spaces is <code>bes_time</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f71b363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = 4.99999999992207e-07 s\n",
      "Standard Deviation = 2.42898975271345e-17 s\n"
     ]
    }
   ],
   "source": [
    "time_diffs = np.diff(bes_time)\n",
    "print(\"Mean =\", np.mean(time_diffs), \"s\\nStandard Deviation =\", np.std(time_diffs), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0303a",
   "metadata": {},
   "source": [
    "The step appears to be highly uniform so the FFT provided by <code>scipy</code> is reasonable to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3054e",
   "metadata": {},
   "source": [
    "Plot full $D_\\alpha$ data, highlighting the regions of interest and storing their data in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11226541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(dalpha_time, dalpha_data, \\'k\\', linewidth=0.5)\\nplt.plot(region_times[0], region_data[0], \"r\", linewidth=0.5)\\nplt.plot(region_times[1], region_data[1], \"g\", linewidth=0.5)\\nplt.plot(region_times[2], region_data[2], \"b\", linewidth=0.5)\\n\\nplt.xlabel(\"Time [s]\")\\nplt.ylabel(r\"Density [m$^{-3}$]\")\\n#plt.savefig(\"Plots/Full_Dalpha_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\\nplt.show()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = [[0.16,0.24], [0.36,0.54], [0.54,0.68]]\n",
    "region_data = []\n",
    "region_times = []\n",
    "\n",
    "for i in range(3):\n",
    "    idx1 = (np.abs(dalpha_time - regions[i][0])).argmin()\n",
    "    idx2 = (np.abs(dalpha_time - regions[i][1])).argmin()\n",
    "    region_data.append(dalpha_data[idx1:idx2+1]) # +1 to include end\n",
    "    region_times.append(dalpha_time[idx1:idx2+1])\n",
    "\n",
    "\"\"\"plt.plot(dalpha_time, dalpha_data, 'k', linewidth=0.5)\n",
    "plt.plot(region_times[0], region_data[0], \"r\", linewidth=0.5)\n",
    "plt.plot(region_times[1], region_data[1], \"g\", linewidth=0.5)\n",
    "plt.plot(region_times[2], region_data[2], \"b\", linewidth=0.5)\n",
    "\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(r\"Density [m$^{-3}$]\")\n",
    "#plt.savefig(\"Plots/Full_Dalpha_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb2e73",
   "metadata": {},
   "source": [
    "Plot $D_\\alpha$ data for each region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "963c6e43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'figure, axes = plt.subplots(3, 1, sharex=False, figsize=(15, 9))\\n\\nfor i in range(3):\\n    idx1 = (np.abs(dalpha_time - regions[i][0])).argmin()\\n    idx2 = (np.abs(dalpha_time - regions[i][1])).argmin()\\n    axes[i].plot(dalpha_time[idx1:idx2], dalpha_data[idx1:idx2], \\'k\\', linewidth=0.8)\\n    axes[i].tick_params(axis=\\'x\\', labelsize=24)\\n    axes[i].tick_params(axis=\\'y\\', labelsize=20)\\n    axes[i].set_ylabel(r\"Region \" + str(i+1) + \"\\nDensity [m$^{-3}$]\", fontsize=20)\\n    axes[i].locator_params(axis=\\'y\\', nbins=3)    \\n\\naxes[-1].set_xlabel(\\'Time [s]\\', fontsize=26)\\nplt.subplots_adjust(hspace=0.5)\\n#plt.savefig(\"Plots/Dalpha_region_plots.pdf\", format=\"pdf\", bbox_inches=\"tight\")\\nplt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"figure, axes = plt.subplots(3, 1, sharex=False, figsize=(15, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    idx1 = (np.abs(dalpha_time - regions[i][0])).argmin()\n",
    "    idx2 = (np.abs(dalpha_time - regions[i][1])).argmin()\n",
    "    axes[i].plot(dalpha_time[idx1:idx2], dalpha_data[idx1:idx2], 'k', linewidth=0.8)\n",
    "    axes[i].tick_params(axis='x', labelsize=24)\n",
    "    axes[i].tick_params(axis='y', labelsize=20)\n",
    "    axes[i].set_ylabel(r\"Region \" + str(i+1) + \"\\nDensity [m$^{-3}$]\", fontsize=20)\n",
    "    axes[i].locator_params(axis='y', nbins=3)    \n",
    "\n",
    "axes[-1].set_xlabel('Time [s]', fontsize=26)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "#plt.savefig(\"Plots/Dalpha_region_plots.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f01745",
   "metadata": {},
   "source": [
    "Function to determine if a given point lies inside the separatrix. Not visually tested on all extreme cases but seems to work. The warning 'UserWarning: No contour levels were found within the data range.' - this just means the contour is too far to the left at that time. A problem in some special cases e.g. at end of region 3. Over the times that will be useful for analysis there should be a contour in the vicinity so this warning shouldn't occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99121f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_sep(equilib_R, equilib_Z, equilib_psi_t, apdpos):\n",
    "    contains = []\n",
    "    \n",
    "    # Only looking for points in the relevant z and right of array's left-most point\n",
    "    # Add on bits to extend contour far enough\n",
    "    zmin = np.abs(np.min(apdpos[:,1])-equilib_Z-0.1).argmin()\n",
    "    zmax = np.abs(np.max(apdpos[:,1])-equilib_Z+0.1).argmin()\n",
    "    rmin = np.abs(np.min(apdpos[:,0])-equilib_R-0.1).argmin()\n",
    "    \n",
    "    # Get path of separatrix\n",
    "    CS = plt.contour(equilib_R[rmin:], equilib_Z[zmin:zmax], equilib_psi_t[zmin:zmax,rmin:], [1.0])\n",
    "    plt.close()\n",
    "    path = mplPath.Path(CS.allsegs[0][0])\n",
    "    \n",
    "    # Extrapolate to get more coordinates\n",
    "    verts = path.vertices\n",
    "    verts_expanded = []\n",
    "    idx = 0\n",
    "    for i in verts[:-1]:\n",
    "        for r in np.linspace(verts[idx,0],verts[idx+1,0],100): # Get lots of points\n",
    "            verts_expanded.append([r, np.interp(r, verts[idx:idx+2,0], verts[idx:idx+2,1])])\n",
    "        idx += 1\n",
    "    verts_expanded = np.asarray(verts_expanded)\n",
    "    \n",
    "    # Find r-coord of point closest in z to channel and test if it's further out\n",
    "    for ch in apdpos:\n",
    "        closest_r = verts_expanded[np.abs(verts_expanded[:,1]-ch[1]).argmin(),0]\n",
    "        if closest_r > ch[0]:\n",
    "            contains.append(True)\n",
    "            #plt.scatter(ch[0], ch[1], color=\"g\")\n",
    "        else:\n",
    "            contains.append(False)\n",
    "            #plt.scatter(ch[0], ch[1], color=\"r\")\n",
    "            \n",
    "    return np.asarray(contains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26a422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inside_sep(equilib_R, equilib_Z, equilib_psi[116], apdpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146318a",
   "metadata": {},
   "source": [
    "We want a to be able to find out which columns are always inside separatrix for each region, and how much of each row is always inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee15db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_times_equilib = []\n",
    "for region in regions:\n",
    "    idx1 = (np.abs(equilib_time - region[0])).argmin()\n",
    "    idx2 = (np.abs(equilib_time - region[1])).argmin()\n",
    "    region_times_equilib.append(np.arange(idx1,idx2+1,1)) # Need +1 to include end point\n",
    "region_times_equilib[2] = region_times_equilib[2][:-1] # Handle special case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9b485",
   "metadata": {},
   "source": [
    "Function to determine which channels are always within separatrix for a given region. A refined version could be something like where is True the case most of the time. Avoid excluding a column because of contour at one point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3525a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_sep_all_time(region):\n",
    "    region = region -1\n",
    "    all_time = [True for i in range(32)]\n",
    "    for time in region_times_equilib[region]:\n",
    "        this_time = inside_sep(equilib_R, equilib_Z, equilib_psi[time], apdpos)\n",
    "        for ch in range(32):\n",
    "            if this_time[ch] == False:\n",
    "                all_time[ch] = False\n",
    "    all_time = np.asarray(all_time)\n",
    "    return all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd90c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for region in range(1,4):\n",
    "#    print(inside_sep_all_time(region).reshape(4,8), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220af12",
   "metadata": {},
   "source": [
    "Function to say whether or not a given column is always inside separatrix for a given region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6227deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_col_good(region, col): # region and col start from 1\n",
    "    all_time = inside_sep_all_time(region)\n",
    "    region = region-1\n",
    "    col = col-1\n",
    "    \n",
    "    this_col = [all_time[ch] for ch in np.arange(col,32,8)]\n",
    "    if False not in this_col:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b7072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(1,4):\\n    for col in range(1,9):\\n        print(check_col_good(region,col))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(1,4):\n",
    "    for col in range(1,9):\n",
    "        print(check_col_good(region,col))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7b228",
   "metadata": {},
   "source": [
    "This says first 2 cols are good for regions 1 & 2, and first 3 cols for region 3. Will include some cols where channel is juuuust inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7adf1",
   "metadata": {},
   "source": [
    "Function to say how much of a row is always inside separatrix for a given region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4025cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_row_lim(region, row): # region and col start from 1\n",
    "    all_time = inside_sep_all_time(region)\n",
    "    region = region-1\n",
    "    row = row-1\n",
    "    \n",
    "    chans = [ch for ch in range(8*row,8*row+8)]\n",
    "    this_row = [all_time[ch] for ch in chans]\n",
    "    if False in this_row:\n",
    "        return this_row.index(False)-1 # Return one before False, i.e. the last True\n",
    "    else:\n",
    "        return chans[-1] # All channels always inside. Return index of the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fe25787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for region in range(1,4):\\n    for row in range(1,5):\\n        print(\"Region\", region, \", row\", row, check_row_lim(region,row))\\n    print(\"\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for region in range(1,4):\n",
    "    for row in range(1,5):\n",
    "        print(\"Region\", region, \", row\", row, check_row_lim(region,row))\n",
    "    print(\"\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5bd549",
   "metadata": {},
   "source": [
    "This says: for region 1, the first 2 channels of each row are always inside. For region 2 it's the same, but rows 1&2 have 3 inside. For region 3, all have first 3 with rows 1&2 also having another, for 4 total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a98585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_bes_fluct_spectrogram(29378, bes_time, fluct_data, [i for i in range(32)], [bes_time[0], bes_time[-1]], 8, \"full\", threshold=0.54)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286559c",
   "metadata": {},
   "source": [
    "Might a bandpass filter be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d27874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_channel( # A. Caplan, this isn't new, just a modified get_channel_fft()\n",
    "        bes_time, fluct_data, timeslice):\n",
    "    idx1 = (np.abs(bes_time - timeslice[0])).argmin()\n",
    "    idx2 = (np.abs(bes_time - timeslice[1])).argmin()\n",
    "    \n",
    "    ps_bes = np.fft.fft(fluct_data[idx1:idx2])\n",
    "    time_step_bes = bes_time[idx1+1] - bes_time[idx1]\n",
    "    freqs_bes = np.fft.fftfreq(fluct_data[idx1:idx2].size, \n",
    "                               time_step_bes)\n",
    "    idx_bes = np.argsort(freqs_bes)\n",
    "    \n",
    "    return [(1.0e-3*freqs_bes[idx_bes]), (ps_bes[idx_bes])] # Note conversion to kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6fd13e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(bes_time, fluct_data[0])\\nfilt = butter_bandpass_filter(fluct_data[0], (0.5 * f_samp)/100, 250.0e3, f_samp)\\n\\ntrans_norm = fft_channel(bes_time, fluct_data[0], [bes_time[0], bes_time[-1]])\\ntrans_filt = fft_channel(bes_time, filt, [bes_time[0], bes_time[-1]])\\n\\nplt.plot(trans_norm[0], np.log(np.abs(trans_norm[1])**2), linewidth=0.1)\\n#plt.xlim(left=-500, right=500)\\nplt.show()\\n\\nplt.plot(trans_filt[0], np.log(np.abs(trans_filt[1])**2), linewidth=0.1)\\n#plt.xlim(left=-500, right=500)\\nplt.show()\\n\\nplt.close()'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.plot(bes_time, fluct_data[0])\n",
    "filt = butter_bandpass_filter(fluct_data[0], (0.5 * f_samp)/100, 250.0e3, f_samp)\n",
    "\n",
    "trans_norm = fft_channel(bes_time, fluct_data[0], [bes_time[0], bes_time[-1]])\n",
    "trans_filt = fft_channel(bes_time, filt, [bes_time[0], bes_time[-1]])\n",
    "\n",
    "plt.plot(trans_norm[0], np.log(np.abs(trans_norm[1])**2), linewidth=0.1)\n",
    "#plt.xlim(left=-500, right=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trans_filt[0], np.log(np.abs(trans_filt[1])**2), linewidth=0.1)\n",
    "#plt.xlim(left=-500, right=500)\n",
    "plt.show()\n",
    "\n",
    "plt.close()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7b9b5",
   "metadata": {},
   "source": [
    "Make plots of short-time FFT for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "509a50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(3):\n",
    "#    plot_bes_fluct_spectrogram(29378, bes_time, fluct_data, [i for i in range(32)], [regions[i][0],regions[i][1]], 8, \"reg_\" + str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcd430",
   "metadata": {},
   "source": [
    "Function to compute how far on average a BES column is in the SOL over a given timeslice. Negative means inside separatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe5ebf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sol_dist(equilib_time, equilib_R, equilib_Z, equilib_psi, timeslice, col, apdpos):   \n",
    "    # Only looking for points in the relevant z and right of array's left-most point\n",
    "    # Add on bits to ensure the contour extends far enough\n",
    "    zmin = np.abs(np.min(apdpos[:,1])-equilib_Z-0.1).argmin()\n",
    "    zmax = np.abs(np.max(apdpos[:,1])-equilib_Z+0.1).argmin()\n",
    "    rmin = np.abs(np.min(apdpos[:,0])-equilib_R-0.1).argmin()\n",
    "    \n",
    "    # Convert timeslice to indices of equilib_time\n",
    "    if isinstance(timeslice, list) or isinstance(timeslice, np.ndarray):\n",
    "        idx1 = np.abs(equilib_time-timeslice[0]).argmin()\n",
    "        idx2 = np.abs(equilib_time-timeslice[1]).argmin()\n",
    "    else:\n",
    "        idx1 = np.abs(equilib_time-timeslice).argmin()\n",
    "        idx2 = idx1\n",
    "    \n",
    "    # Get coordinates of each channel in the specified column\n",
    "    ch_pos = [apdpos[ch] for ch in np.arange(col,32,8)]\n",
    "    \n",
    "    all_time = [] # Stores averages distances for each time\n",
    "    for time in range(idx1, idx2+1):\n",
    "        # Get path of separatrix\n",
    "        equilib_psi_t = equilib_psi[time] # Data at this time\n",
    "        CS = plt.contour(equilib_R[rmin:], equilib_Z[zmin:zmax], equilib_psi_t[zmin:zmax,rmin:], [1.0])\n",
    "        plt.close()\n",
    "        path = mplPath.Path(CS.allsegs[0][0])\n",
    "\n",
    "        # Extrapolate to get more coordinates\n",
    "        verts = path.vertices\n",
    "        verts_expanded = []\n",
    "        idx = 0\n",
    "        for i in verts[:-1]:\n",
    "            for r in np.linspace(verts[idx,0],verts[idx+1,0],100): # Get lots of points\n",
    "                verts_expanded.append([r, np.interp(r, verts[idx:idx+2,0], verts[idx:idx+2,1])])\n",
    "            idx += 1\n",
    "        verts_expanded = np.asarray(verts_expanded)\n",
    "\n",
    "        # Find r-coord of point closest in z to channel and find dist to separatrix\n",
    "        this_time = []\n",
    "        for ch in ch_pos:\n",
    "            closest_r = verts_expanded[np.abs(verts_expanded[:,1]-ch[1]).argmin(),0]\n",
    "            this_time.append(ch[0] - closest_r)\n",
    "        all_time.append(np.mean(this_time))\n",
    "    return np.mean(all_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a018853",
   "metadata": {},
   "source": [
    "Saving some results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5180ad9e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col 0 -0.07268894997833482 m\n",
      "Col 1 -0.053035720786061655 m\n",
      "Col 2 -0.033804819251146714 m\n",
      "Col 3 -0.014922848975031025 m\n",
      "Col 4 0.003539637982023852 m\n",
      "Col 5 0.02171765922608923 m\n",
      "Col 6 0.03952210562695404 m\n",
      "Col 7 0.05703609196745006 m\n",
      "Col 0 -0.08364023800637495 m\n",
      "Col 1 -0.06398244520955756 m\n",
      "Col 2 -0.044764389925549514 m\n",
      "Col 3 -0.025890044951594995 m\n",
      "Col 4 -0.007403325599800001 m\n",
      "Col 5 0.010755219703541676 m\n",
      "Col 6 0.028580495845223628 m\n",
      "Col 7 0.046075747089316964 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamc\\AppData\\Local\\Temp\\ipykernel_4436\\3088208760.py:23: UserWarning: No contour levels were found within the data range.\n",
      "  CS = plt.contour(equilib_R[rmin:], equilib_Z[zmin:zmax], equilib_psi_t[zmin:zmax,rmin:], [1.0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col 0 -0.0825355122871143 m\n",
      "Col 1 -0.06289764033322905 m\n",
      "Col 2 -0.04367393750235058 m\n",
      "Col 3 -0.024794317462004355 m\n",
      "Col 4 -0.006319466010721457 m\n",
      "Col 5 0.011857595329280834 m\n",
      "Col 6 0.029683485665038135 m\n",
      "Col 7 0.04716410507715141 m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"with open(\"dist_in_sol_new.csv\", \"w\") as f:\n",
    "    for region in range(3):\n",
    "        f.write(\"Region\" + str(region+1) + \"\\n\")\n",
    "        for col in range(8):\n",
    "            f.write(str(sol_dist(equilib_time, equilib_R, equilib_Z, equilib_psi, regions[region], col, apdpos)) + \",\")\n",
    "            print(\"Col\", col, sol_dist(equilib_time, equilib_R, equilib_Z, equilib_psi, regions[region], col, apdpos), \"m\")\n",
    "        f.write(\"\\n\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
